{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1650b3d",
   "metadata": {},
   "source": [
    "# Embedding Ratings - Skip Gram Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05692741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Other\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.sparse import csr_matrix, lil_matrix, vstack, load_npz\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "tf.config.run_functions_eagerly(True)\n",
    "#tf.data.experimental.enable_debug_mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497e292e",
   "metadata": {},
   "source": [
    "## Classes and Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016f1155",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingRatings:\n",
    "    def __init__(self, hidden_dim: int, k: int, input_dim: int):\n",
    "        self.input_dim = input_dim\n",
    "        input_vec = keras.Input(shape=(self.input_dim,))\n",
    "        encoded = layers.Dense(hidden_dim, activation='relu')(input_vec)\n",
    "        decoded = layers.Dense(input_dim, activation='relu')(encoded)\n",
    "        \n",
    "        self.autoencoder = keras.Model(input_vec, decoded)\n",
    "        self.encoder = keras.Model(input_vec, encoded)\n",
    "        self.autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "        \n",
    "        self.knn = NearestNeighbors(metric='cosine', n_neighbors=k)\n",
    "    \n",
    "    def fit(self, training_ratings, generator, epochs):\n",
    "        self.training_ratings = training_ratings\n",
    "        \n",
    "        print('Fitting autoencoder...')\n",
    "        # Batch size determined in generator constructor\n",
    "        self.autoencoder.fit(generator, \n",
    "                             epochs=epochs,\n",
    "                             shuffle=True)\n",
    "        \n",
    "        print('Creating embeddings...')\n",
    "        self.embeddings = self.encoder.predict(self.training_ratings)\n",
    "        self.knn.fit(self.embeddings)\n",
    "        \n",
    "    def predict(self, user_ratings):\n",
    "        print('Embedding test users...')\n",
    "        pred_embeddings = self.encoder.predict(user_ratings)\n",
    "        \n",
    "        print('Performing nearest-neighbor search in embedding space...')\n",
    "        user_neighbors = self.knn.kneighbors(pred_embeddings, return_distance=False)\n",
    "        \n",
    "        print('Aggregating neighbor ratings...')\n",
    "        pred = lil_matrix(user_ratings.shape)\n",
    "        for idx, neighbor_indices in tqdm(enumerate(user_neighbors), total=user_neighbors.shape[0]):\n",
    "            neighbors = self.training_ratings[neighbor_indices]\n",
    "            divisor = neighbors.getnnz(axis=0)\n",
    "            divisor[divisor == 0] = 1\n",
    "            pred[idx] = neighbors.sum(axis=0) / divisor\n",
    " \n",
    "        return pred.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04b4a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipGramDataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, contexts, targets, batch_size):\n",
    "        self.contexts = contexts\n",
    "        self.targets = targets\n",
    "        self.batch_size = batch_size\n",
    "        self.indices = np.arange(contexts.shape[0])\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.contexts.shape[0] / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_indices = self.indices[idx * self.batch_size : (idx + 1) * self.batch_size]\n",
    "        context_batch = self.contexts[batch_indices].toarray()\n",
    "        targets_batch = self.targets[batch_indices].toarray()\n",
    "        return context_batch, targets_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c223e539",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seen_unseen_split(ratings, fraction_seen=0.8):\n",
    "    seen = lil_matrix(ratings.shape)\n",
    "    unseen = lil_matrix(ratings.shape)\n",
    "\n",
    "    for user_id in tqdm(range(ratings.shape[0])):\n",
    "        rated_items_indices = ratings[user_id].nonzero()[1]\n",
    "        np.random.shuffle(rated_items_indices)\n",
    "        num_seen_items = int(fraction_seen * len(rated_items_indices))\n",
    "\n",
    "        seen[user_id, rated_items_indices[:num_seen_items]] = ratings[user_id, rated_items_indices[:num_seen_items]]\n",
    "        unseen[user_id, rated_items_indices[num_seen_items:]] = ratings[user_id, rated_items_indices[num_seen_items:]]\n",
    "\n",
    "    return seen.tocsr(), unseen.tocsr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99321399",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b5164d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_train = load_npz(\"data/sessions_train.npz\")\n",
    "sessions_test = load_npz(\"data/sessions_test.npz\")\n",
    "\n",
    "# Cached context/target pairs generated from training sessions\n",
    "session_train_contexts = load_npz(\"data/session_train_contexts.npz\")\n",
    "session_train_targets = load_npz(\"data/session_train_targets.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426fc24c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seen, unseen = seen_unseen_split(sessions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5f4825",
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_train.shape, session_train_contexts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232ae510",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d83b050",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f352485",
   "metadata": {},
   "outputs": [],
   "source": [
    "er = EmbeddingRatings(hidden_dim=128, k=250, input_dim=sessions_train.shape[1])\n",
    "er.autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd1e7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = SkipGramDataGenerator(session_train_contexts, session_train_targets, batch_size=256)\n",
    "er.fit(sessions_train, generator, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdaccb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "er.embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ec29e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = er.predict(seen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fce6ce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "output = np.asarray(pred[unseen.nonzero()]).flatten() # Predictions lined up with unseen\n",
    "#plt.scatter(unseen.data, output)\n",
    "sns.boxenplot(x=unseen.data, y=output)\n",
    "plt.xlabel('True Ratings')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Predicted Ratings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bde959",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "RMSE = root_mean_squared_error(unseen.data, output)\n",
    "correlation_coefficient, _ = pearsonr(unseen.data, output)\n",
    "print(f\"RMSE: {RMSE}\\nR2: {correlation_coefficient ** 2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03dfca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "frac_nonzero_ratings = pred.nnz / np.prod(pred.shape)\n",
    "frac_ratings_predicted = len(output.nonzero()[0]) / len(output)\n",
    "print(f\"Percent Nonzero: {frac_nonzero_ratings * 100}\\nRecall (% unseen ratings predicted): {frac_ratings_predicted * 100}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
